{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TIwd1Bp2itq",
        "outputId": "551e82c6-a1e9-4c08-834b-7684a1cb9f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4 scipy-1.15.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.3.20+ds-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade numpy scipy scikit-learn\n",
        "!sudo apt install libopenblas-dev  # Install BLAS backend"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## ML Energy Efficiency Analysis in Colab\n",
        "\n",
        "# %% [code]\n",
        "# Install required packages\n",
        "!pip install psutil  # Needed for system monitoring\n",
        "\n",
        "# %% [code]\n",
        "import numpy as np\n",
        "import time\n",
        "import psutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# %% [code]\n",
        "class EnergyEfficiencyAnalyzer:\n",
        "    def __init__(self, output_dir):\n",
        "        self.results = {\n",
        "            'architectures': [],\n",
        "            'training_time': [],\n",
        "            'energy_consumption': [],\n",
        "            'accuracy': []\n",
        "        }\n",
        "        self.output_dir = output_dir\n",
        "\n",
        "    def generate_dataset(self, n_samples=1000, n_features=10):\n",
        "        np.random.seed(42)\n",
        "        X = np.random.randn(n_samples, n_features)\n",
        "        y = (X[:, 0] + X[:, 1] > 0).astype(int)\n",
        "        return X, y\n",
        "\n",
        "    def measure_ml_performance(self, X, y):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        start_cpu = psutil.cpu_percent()\n",
        "        start_memory = psutil.virtual_memory().used\n",
        "        start_time = time.time()\n",
        "\n",
        "        model = MLPClassifier(\n",
        "            hidden_layer_sizes=(64, 32),\n",
        "            max_iter=100,\n",
        "            random_state=42\n",
        "        )\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        end_time = time.time()\n",
        "        end_cpu = psutil.cpu_percent()\n",
        "        end_memory = psutil.virtual_memory().used\n",
        "\n",
        "        training_time = end_time - start_time\n",
        "        cpu_usage = end_cpu - start_cpu\n",
        "        memory_usage = end_memory - start_memory\n",
        "\n",
        "        accuracy = model.score(X_test_scaled, y_test)\n",
        "        energy_proxy = (cpu_usage * memory_usage) / 1e9\n",
        "\n",
        "        self.results['architectures'].append('MLP Classifier')\n",
        "        self.results['training_time'].append(training_time)\n",
        "        self.results['energy_consumption'].append(energy_proxy)\n",
        "        self.results['accuracy'].append(accuracy)\n",
        "\n",
        "        return {\n",
        "            'training_time': training_time,\n",
        "            'energy_proxy': energy_proxy,\n",
        "            'accuracy': accuracy\n",
        "        }\n",
        "\n",
        "    def visualize_results(self):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(131)\n",
        "        plt.scatter(self.results['training_time'], self.results['energy_consumption'])\n",
        "        plt.title('Training Time vs Energy')\n",
        "\n",
        "        plt.subplot(132)\n",
        "        plt.bar(self.results['architectures'], self.results['accuracy'])\n",
        "        plt.title('Model Accuracy')\n",
        "\n",
        "        plt.subplot(133)\n",
        "        efficiency_ratio = [acc/energy if energy > 0 else 0\n",
        "                          for acc, energy in zip(self.results['accuracy'],\n",
        "                                               self.results['energy_consumption'])]\n",
        "        plt.bar(self.results['architectures'], efficiency_ratio)\n",
        "        plt.title('Accuracy/Energy Efficiency')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plot_path = os.path.join(self.output_dir, 'ml_energy_efficiency.png')\n",
        "        plt.savefig(plot_path)\n",
        "        plt.close()\n",
        "\n",
        "        # Display in notebook\n",
        "        display(Markdown(f\"**Saved plot to:** `{plot_path}`\"))\n",
        "        display(plt.imread(plot_path))\n",
        "\n",
        "    def generate_report(self):\n",
        "        report_data = {\n",
        "            'Total Runs': len(self.results['architectures']),\n",
        "            'Average Training Time': np.mean(self.results['training_time']),\n",
        "            'Average Energy Consumption': np.mean(self.results['energy_consumption']),\n",
        "            'Average Accuracy': np.mean(self.results['accuracy'])\n",
        "        }\n",
        "\n",
        "        report_path = os.path.join(self.output_dir, 'performance_report.txt')\n",
        "        with open(report_path, 'w') as f:\n",
        "            f.write(\"Machine Learning Energy Efficiency Report\\n\")\n",
        "            f.write(\"=========================================\\n\\n\")\n",
        "            for key, value in report_data.items():\n",
        "                f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "        # Display report contents\n",
        "        display(Markdown(f\"**Report generated at:** `{report_path}`\"))\n",
        "        with open(report_path, 'r') as f:\n",
        "            display(Markdown(f\"```\\n{f.read()}\\n```\"))\n",
        "\n",
        "        return report_data\n",
        "\n",
        "# %% [code]\n",
        "# Main execution\n",
        "output_dir = \"/content/energy_efficiency_analysis\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "analyzer = EnergyEfficiencyAnalyzer(output_dir)\n",
        "X, y = analyzer.generate_dataset(n_samples=5000, n_features=10)\n",
        "\n",
        "# Run analysis\n",
        "print(\"🚀 Running ML Performance Analysis...\")\n",
        "results = analyzer.measure_ml_performance(X, y)\n",
        "\n",
        "# Display immediate results\n",
        "display(Markdown(\"### Immediate Results:\"))\n",
        "for metric, value in results.items():\n",
        "    display(Markdown(f\"- **{metric.replace('_', ' ').title()}:** {value:.4f}\"))\n",
        "\n",
        "# Generate visualizations and report\n",
        "analyzer.visualize_results()\n",
        "final_report = analyzer.generate_report()\n",
        "\n",
        "# Final summary\n",
        "display(Markdown(\"### Final Summary:\"))\n",
        "for metric, value in final_report.items():\n",
        "    display(Markdown(f\"- **{metric.replace('_', ' ').title()}:** {value:.4f}\"))\n",
        "\n",
        "# %% [markdown]\n",
        "# ### Accessing Results\n",
        "# - Plots saved to: `/content/energy_efficiency_analysis/ml_energy_efficiency.png`\n",
        "# - Report saved to: `/content/energy_efficiency_analysis/performance_report.txt`\n",
        "#\n",
        "# To download results:\n",
        "# ```python\n",
        "# from google.colab import files\n",
        "# !zip -r results.zip {output_dir}\n",
        "# files.download('results.zip')\n",
        "# ```\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pQJ-60_hfwOg",
        "outputId": "9ed4fb66-90ee-4013-a587-af9cb3c2c21c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "🚀 Running ML Performance Analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Immediate Results:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Training Time:** 8.5737"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Energy Proxy:** 3.5439"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Accuracy:** 0.9910"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Saved plot to:** `/content/energy_efficiency_analysis/ml_energy_efficiency.png`"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]]], dtype=float32)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Report generated at:** `/content/energy_efficiency_analysis/performance_report.txt`"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```\nMachine Learning Energy Efficiency Report\n=========================================\n\nTotal Runs: 1\nAverage Training Time: 8.573732852935791\nAverage Energy Consumption: 3.5439407104000002\nAverage Accuracy: 0.991\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Final Summary:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Total Runs:** 1.0000"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Average Training Time:** 8.5737"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Average Energy Consumption:** 3.5439"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Average Accuracy:** 0.9910"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import baler\n",
        "print(dir(baler))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoUZEuKi4ArB",
        "outputId": "6b0842a7-8198-4cc9-9e13-36f28ef5c6f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'baler', 'modules', 'perform_compression', 'perform_decompression', 'perform_diagnostics', 'perform_plotting', 'perform_training', 'print_info']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create directory if missing\n",
        "!mkdir -p /train_data\n",
        "\n",
        "# 1. Upload your dataset here using Colab's file explorer\n",
        "#    (left sidebar ➔ 📁 folder icon)\n",
        "\n",
        "# 2. Verify dataset structure\n",
        "assert os.path.exists('/train_data'), \"Dataset not found!\"\n",
        "\n",
        "# 3. Create generator\n",
        "calibration_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "calibration_generator = calibration_datagen.flow_from_directory(\n",
        "    '/content/train_data',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"✅ Found {calibration_generator.samples} calibration images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbApRZoQ5jg6",
        "outputId": "ebb0c3c5-0698-447a-c1a6-4470d0931056"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4 images belonging to 3 classes.\n",
            "✅ Found 4 calibration images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First install baler if needed (uncomment if required)\n",
        "# !pip install git+https://github.com/yourusername/baler.git\n",
        "\n",
        "from baler import perform_compression\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load model with proper Colab path\n",
        "try:\n",
        "    model = tf.keras.models.load_model(\"/content/cat_dog_model.h5\")\n",
        "except Exception as e:\n",
        "    raise FileNotFoundError(f\"Model not found at /content/cat_dog_model.h5 - Upload model first!\\n{str(e)}\")\n",
        "\n",
        "# Compression config with validation\n",
        "config = {\n",
        "    'quantization': {\n",
        "        'bits': 8,  # Supported: 8, 16\n",
        "        'per_channel': True\n",
        "    },\n",
        "    'pruning': {\n",
        "        'sparsity': 0.5,  # Between 0-1\n",
        "        'block_size': (1, 1)\n",
        "    },\n",
        "    'format': 'h5'\n",
        "}\n",
        "\n",
        "# Generate calibration data from your prepared generator\n",
        "# Using 10 batches (320 samples) assuming batch_size=32\n",
        "calibration_samples = []\n",
        "for _ in range(10):\n",
        "    batch, _ = next(calibration_generator)\n",
        "    calibration_samples.append(batch)\n",
        "calibration_data = np.concatenate(calibration_samples)\n",
        "\n",
        "# Perform compression with error handling\n",
        "try:\n",
        "    compressed_model = perform_compression(\n",
        "        model=model,\n",
        "        config=config,\n",
        "        calibration_data=calibration_data,  # Now properly defined\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Save with proper permissions\n",
        "    compressed_model.save(\"/content/optimized_cat_dog_model.h5\")\n",
        "    print(\"✅ Compression successful! Saved to /content/optimized_cat_dog_model.h5\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Compression failed: {str(e)}\")\n",
        "    print(\"Common fixes:\")\n",
        "    print(\"1. Check baler installation\")\n",
        "    print(\"2. Verify calibration data shape matches model input\")\n",
        "    print(\"3. Ensure TensorFlow version compatibility\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzj2jxlU22DX",
        "outputId": "c1d0d964-51cc-453f-f20e-0fcf8d735cd8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Compression failed: perform_compression() got an unexpected keyword argument 'model'\n",
            "Common fixes:\n",
            "1. Check baler installation\n",
            "2. Verify calibration data shape matches model input\n",
            "3. Ensure TensorFlow version compatibility\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# Get file sizes\n",
        "original_size = os.path.getsize(\"/content/cat_dog_model.h5\") / 1024  # KB\n",
        "optimized_size = os.path.getsize(\"/content/cat_dog_model_optimized.h5\") / 1024  # KB\n",
        "\n",
        "# Load optimized model\n",
        "opt_model = keras.models.load_model(\"/content/cat_dog_model_optimized.h5\")\n",
        "\n",
        "# Measure inference time\n",
        "def measure_time(model, sample):\n",
        "    start = time.time()\n",
        "    model.predict(sample)\n",
        "    return time.time() - start\n",
        "\n",
        "sample = np.expand_dims(x_test[0], axis=0)\n",
        "\n",
        "original_time = measure_time(model, sample)\n",
        "optimized_time = measure_time(opt_model, sample)\n",
        "\n",
        "# Print comparison\n",
        "print(f\"🔹 Original Model Size: {original_size:.2f} KB\")\n",
        "print(f\"🔹 Optimized Model Size: {optimized_size:.2f} KB\")\n",
        "print(f\"⚡ Inference Time (Original): {original_time:.5f} sec\")\n",
        "print(f\"⚡ Inference Time (Optimized): {optimized_time:.5f} sec\")\n"
      ],
      "metadata": {
        "id": "kBode2We3llN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = [\"Original\", \"Optimized\"]\n",
        "sizes = [original_size, optimized_size]\n",
        "times = [original_time, optimized_time]\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# Storage Reduction\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(labels, sizes, color=[\"red\", \"green\"])\n",
        "plt.ylabel(\"Model Size (KB)\")\n",
        "plt.title(\"Model Storage Optimization\")\n",
        "\n",
        "# Inference Time Reduction\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(labels, times, color=[\"blue\", \"orange\"])\n",
        "plt.ylabel(\"Inference Time (sec)\")\n",
        "plt.title(\"Inference Speed Optimization\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QK7XQpNr3rAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}